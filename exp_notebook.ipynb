{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "a498beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "b0d2d525",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('FidelFolio_Dataset(1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "73d1af0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Company</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "      <th>Feature4</th>\n",
       "      <th>Feature5</th>\n",
       "      <th>Feature6</th>\n",
       "      <th>Feature7</th>\n",
       "      <th>Feature8</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature22</th>\n",
       "      <th>Feature23</th>\n",
       "      <th>Feature24</th>\n",
       "      <th>Feature25</th>\n",
       "      <th>Feature26</th>\n",
       "      <th>Feature27</th>\n",
       "      <th>Feature28</th>\n",
       "      <th>Target 1</th>\n",
       "      <th>Target 2</th>\n",
       "      <th>Target 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>Hind. Unilever</td>\n",
       "      <td>15.0</td>\n",
       "      <td>65.87</td>\n",
       "      <td>54.57</td>\n",
       "      <td>41.12</td>\n",
       "      <td>45.82</td>\n",
       "      <td>123.34</td>\n",
       "      <td>0.65</td>\n",
       "      <td>33131.93</td>\n",
       "      <td>...</td>\n",
       "      <td>19.581982</td>\n",
       "      <td>1192.76</td>\n",
       "      <td>1222.04</td>\n",
       "      <td>1120.99</td>\n",
       "      <td>1091.71</td>\n",
       "      <td>1956.94</td>\n",
       "      <td>264.31</td>\n",
       "      <td>5.38</td>\n",
       "      <td>29.08</td>\n",
       "      <td>42.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>ITC</td>\n",
       "      <td>66.0</td>\n",
       "      <td>35.77</td>\n",
       "      <td>32.29</td>\n",
       "      <td>37.91</td>\n",
       "      <td>36.37</td>\n",
       "      <td>-269.26</td>\n",
       "      <td>0.57</td>\n",
       "      <td>23632.98</td>\n",
       "      <td>...</td>\n",
       "      <td>10.904040</td>\n",
       "      <td>1040.32</td>\n",
       "      <td>1249.28</td>\n",
       "      <td>1146.99</td>\n",
       "      <td>938.03</td>\n",
       "      <td>3486.42</td>\n",
       "      <td>1252.22</td>\n",
       "      <td>-67.4</td>\n",
       "      <td>-23.41</td>\n",
       "      <td>-33.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>79.0</td>\n",
       "      <td>31.40</td>\n",
       "      <td>46.55</td>\n",
       "      <td>164.42</td>\n",
       "      <td>74.72</td>\n",
       "      <td>348.29</td>\n",
       "      <td>1.61</td>\n",
       "      <td>18438.55</td>\n",
       "      <td>...</td>\n",
       "      <td>44.860469</td>\n",
       "      <td>182.67</td>\n",
       "      <td>218.26</td>\n",
       "      <td>153.73</td>\n",
       "      <td>118.14</td>\n",
       "      <td>828.14</td>\n",
       "      <td>281.07</td>\n",
       "      <td>538.95</td>\n",
       "      <td>60.23</td>\n",
       "      <td>108.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999</td>\n",
       "      <td>O N G C</td>\n",
       "      <td>37.0</td>\n",
       "      <td>13.78</td>\n",
       "      <td>11.82</td>\n",
       "      <td>6.12</td>\n",
       "      <td>3.23</td>\n",
       "      <td>6.02</td>\n",
       "      <td>1.19</td>\n",
       "      <td>16868.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695653</td>\n",
       "      <td>4269.99</td>\n",
       "      <td>5100.39</td>\n",
       "      <td>4404.90</td>\n",
       "      <td>3574.50</td>\n",
       "      <td>32398.94</td>\n",
       "      <td>8150.14</td>\n",
       "      <td>-29.06</td>\n",
       "      <td>4.07</td>\n",
       "      <td>124.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999</td>\n",
       "      <td>Lila Worldwide</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.14</td>\n",
       "      <td>5,715.31</td>\n",
       "      <td>-4.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1,094.90</td>\n",
       "      <td>14916.95</td>\n",
       "      <td>...</td>\n",
       "      <td>4.154480</td>\n",
       "      <td>4.59</td>\n",
       "      <td>4.77</td>\n",
       "      <td>3.09</td>\n",
       "      <td>2.91</td>\n",
       "      <td>3590.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.06</td>\n",
       "      <td>598.24</td>\n",
       "      <td>1,057.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year         Company  Feature1  Feature2  Feature3  Feature4 Feature5  \\\n",
       "0  1999  Hind. Unilever      15.0     65.87     54.57     41.12    45.82   \n",
       "1  1999             ITC      66.0     35.77     32.29     37.91    36.37   \n",
       "2  1999           Wipro      79.0     31.40     46.55    164.42    74.72   \n",
       "3  1999         O N G C      37.0     13.78     11.82      6.12     3.23   \n",
       "4  1999  Lila Worldwide       NaN      0.16      0.14  5,715.31    -4.41   \n",
       "\n",
       "  Feature6   Feature7  Feature8  ...  Feature22  Feature23  Feature24  \\\n",
       "0   123.34       0.65  33131.93  ...  19.581982    1192.76    1222.04   \n",
       "1  -269.26       0.57  23632.98  ...  10.904040    1040.32    1249.28   \n",
       "2   348.29       1.61  18438.55  ...  44.860469     182.67     218.26   \n",
       "3     6.02       1.19  16868.75  ...   0.695653    4269.99    5100.39   \n",
       "4      NaN  -1,094.90  14916.95  ...   4.154480       4.59       4.77   \n",
       "\n",
       "   Feature25  Feature26  Feature27  Feature28   Target 1    Target 2   \\\n",
       "0    1120.99    1091.71    1956.94     264.31        5.38       29.08   \n",
       "1    1146.99     938.03    3486.42    1252.22       -67.4      -23.41   \n",
       "2     153.73     118.14     828.14     281.07      538.95       60.23   \n",
       "3    4404.90    3574.50   32398.94    8150.14      -29.06        4.07   \n",
       "4       3.09       2.91    3590.57        NaN      150.06      598.24   \n",
       "\n",
       "    Target 3   \n",
       "0       42.37  \n",
       "1      -33.87  \n",
       "2       108.3  \n",
       "3      124.85  \n",
       "4    1,057.39  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "8b297884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2796"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Company'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "ae31c8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24751, 33)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "b2785686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1999,\n",
       " 2000,\n",
       " 2001,\n",
       " 2002,\n",
       " 2003,\n",
       " 2004,\n",
       " 2005,\n",
       " 2006,\n",
       " 2007,\n",
       " 2008,\n",
       " 2009,\n",
       " 2010,\n",
       " 2011,\n",
       " 2012,\n",
       " 2013,\n",
       " 2014,\n",
       " 2015,\n",
       " 2016,\n",
       " 2017,\n",
       " 2018,\n",
       " 2019,\n",
       " 2020,\n",
       " 2021,\n",
       " 2022,\n",
       " 2023,\n",
       " 2024]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Year'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "34ba6feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values(by=['Company','Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "27ea67d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Company</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "      <th>Feature4</th>\n",
       "      <th>Feature5</th>\n",
       "      <th>Feature6</th>\n",
       "      <th>Feature7</th>\n",
       "      <th>Feature8</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature22</th>\n",
       "      <th>Feature23</th>\n",
       "      <th>Feature24</th>\n",
       "      <th>Feature25</th>\n",
       "      <th>Feature26</th>\n",
       "      <th>Feature27</th>\n",
       "      <th>Feature28</th>\n",
       "      <th>Target 1</th>\n",
       "      <th>Target 2</th>\n",
       "      <th>Target 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18959</th>\n",
       "      <td>2020</td>\n",
       "      <td>360 ONE</td>\n",
       "      <td>253.00</td>\n",
       "      <td>7.56</td>\n",
       "      <td>6.82</td>\n",
       "      <td>42.78</td>\n",
       "      <td>5.29</td>\n",
       "      <td>-4.97</td>\n",
       "      <td>2.07</td>\n",
       "      <td>8606.08</td>\n",
       "      <td>...</td>\n",
       "      <td>2.876844</td>\n",
       "      <td>327.44</td>\n",
       "      <td>829.03</td>\n",
       "      <td>788.01</td>\n",
       "      <td>286.42</td>\n",
       "      <td>8197.71</td>\n",
       "      <td>8838.10</td>\n",
       "      <td>-51.37</td>\n",
       "      <td>-39.33</td>\n",
       "      <td>-32.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20893</th>\n",
       "      <td>2021</td>\n",
       "      <td>360 ONE</td>\n",
       "      <td>239.00</td>\n",
       "      <td>9.11</td>\n",
       "      <td>12.69</td>\n",
       "      <td>29.52</td>\n",
       "      <td>23.55</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.51</td>\n",
       "      <td>10897.02</td>\n",
       "      <td>...</td>\n",
       "      <td>3.853574</td>\n",
       "      <td>527.89</td>\n",
       "      <td>941.44</td>\n",
       "      <td>898.47</td>\n",
       "      <td>484.92</td>\n",
       "      <td>4234.86</td>\n",
       "      <td>5076.69</td>\n",
       "      <td>18.58</td>\n",
       "      <td>24.03</td>\n",
       "      <td>72.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22046</th>\n",
       "      <td>2022</td>\n",
       "      <td>360 ONE</td>\n",
       "      <td>1.86</td>\n",
       "      <td>13.40</td>\n",
       "      <td>19.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.83</td>\n",
       "      <td>14825.74</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>793.04</td>\n",
       "      <td>1162.89</td>\n",
       "      <td>1121.15</td>\n",
       "      <td>751.30</td>\n",
       "      <td>4914.95</td>\n",
       "      <td>5807.58</td>\n",
       "      <td>5.24</td>\n",
       "      <td>37.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22474</th>\n",
       "      <td>2023</td>\n",
       "      <td>360 ONE</td>\n",
       "      <td>2.05</td>\n",
       "      <td>13.34</td>\n",
       "      <td>21.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>15342.12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>896.60</td>\n",
       "      <td>1295.80</td>\n",
       "      <td>1249.49</td>\n",
       "      <td>850.29</td>\n",
       "      <td>5001.57</td>\n",
       "      <td>6783.67</td>\n",
       "      <td>29.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23731</th>\n",
       "      <td>2024</td>\n",
       "      <td>360 ONE</td>\n",
       "      <td>2.47</td>\n",
       "      <td>14.47</td>\n",
       "      <td>24.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>24221.43</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1065.18</td>\n",
       "      <td>1708.67</td>\n",
       "      <td>1652.03</td>\n",
       "      <td>1008.54</td>\n",
       "      <td>6554.96</td>\n",
       "      <td>9471.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1999</td>\n",
       "      <td>3M India</td>\n",
       "      <td>83.00</td>\n",
       "      <td>18.59</td>\n",
       "      <td>19.54</td>\n",
       "      <td>41.83</td>\n",
       "      <td>24.75</td>\n",
       "      <td>43.72</td>\n",
       "      <td>0.97</td>\n",
       "      <td>329.65</td>\n",
       "      <td>...</td>\n",
       "      <td>7.446352</td>\n",
       "      <td>11.38</td>\n",
       "      <td>15.83</td>\n",
       "      <td>13.67</td>\n",
       "      <td>9.22</td>\n",
       "      <td>74.01</td>\n",
       "      <td>29.74</td>\n",
       "      <td>55.24</td>\n",
       "      <td>117.63</td>\n",
       "      <td>-14.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>2000</td>\n",
       "      <td>3M India</td>\n",
       "      <td>64.00</td>\n",
       "      <td>13.04</td>\n",
       "      <td>2.33</td>\n",
       "      <td>840.91</td>\n",
       "      <td>163.57</td>\n",
       "      <td>298.14</td>\n",
       "      <td>0.56</td>\n",
       "      <td>655.91</td>\n",
       "      <td>...</td>\n",
       "      <td>14.559600</td>\n",
       "      <td>7.14</td>\n",
       "      <td>9.84</td>\n",
       "      <td>7.14</td>\n",
       "      <td>4.44</td>\n",
       "      <td>72.16</td>\n",
       "      <td>27.11</td>\n",
       "      <td>38.26</td>\n",
       "      <td>-28.02</td>\n",
       "      <td>-12.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>2001</td>\n",
       "      <td>3M India</td>\n",
       "      <td>71.00</td>\n",
       "      <td>28.42</td>\n",
       "      <td>21.32</td>\n",
       "      <td>69.18</td>\n",
       "      <td>1,430.21</td>\n",
       "      <td>-38.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>743.71</td>\n",
       "      <td>...</td>\n",
       "      <td>13.328136</td>\n",
       "      <td>24.80</td>\n",
       "      <td>29.19</td>\n",
       "      <td>24.43</td>\n",
       "      <td>20.04</td>\n",
       "      <td>99.86</td>\n",
       "      <td>44.06</td>\n",
       "      <td>-57.91</td>\n",
       "      <td>-39.35</td>\n",
       "      <td>-75.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2339</th>\n",
       "      <td>2002</td>\n",
       "      <td>3M India</td>\n",
       "      <td>63.00</td>\n",
       "      <td>27.81</td>\n",
       "      <td>22.01</td>\n",
       "      <td>21.81</td>\n",
       "      <td>20.74</td>\n",
       "      <td>25.24</td>\n",
       "      <td>0.51</td>\n",
       "      <td>300.91</td>\n",
       "      <td>...</td>\n",
       "      <td>4.323420</td>\n",
       "      <td>29.26</td>\n",
       "      <td>34.45</td>\n",
       "      <td>28.38</td>\n",
       "      <td>23.19</td>\n",
       "      <td>104.25</td>\n",
       "      <td>34.65</td>\n",
       "      <td>27.42</td>\n",
       "      <td>39.16</td>\n",
       "      <td>37.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>2003</td>\n",
       "      <td>3M India</td>\n",
       "      <td>25.00</td>\n",
       "      <td>33.44</td>\n",
       "      <td>22.77</td>\n",
       "      <td>19.44</td>\n",
       "      <td>10.43</td>\n",
       "      <td>11.21</td>\n",
       "      <td>1.02</td>\n",
       "      <td>340.97</td>\n",
       "      <td>...</td>\n",
       "      <td>4.035626</td>\n",
       "      <td>35.74</td>\n",
       "      <td>38.04</td>\n",
       "      <td>32.15</td>\n",
       "      <td>29.85</td>\n",
       "      <td>88.01</td>\n",
       "      <td>3.52</td>\n",
       "      <td>-8.16</td>\n",
       "      <td>-15.63</td>\n",
       "      <td>-63.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year   Company  Feature1  Feature2  Feature3 Feature4  Feature5  \\\n",
       "18959  2020   360 ONE    253.00      7.56      6.82    42.78      5.29   \n",
       "20893  2021   360 ONE    239.00      9.11     12.69    29.52     23.55   \n",
       "22046  2022   360 ONE      1.86     13.40     19.75      NaN       NaN   \n",
       "22474  2023   360 ONE      2.05     13.34     21.41      NaN       NaN   \n",
       "23731  2024   360 ONE      2.47     14.47     24.48      NaN       NaN   \n",
       "176    1999  3M India     83.00     18.59     19.54    41.83     24.75   \n",
       "860    2000  3M India     64.00     13.04      2.33   840.91    163.57   \n",
       "1593   2001  3M India     71.00     28.42     21.32    69.18  1,430.21   \n",
       "2339   2002  3M India     63.00     27.81     22.01    21.81     20.74   \n",
       "2980   2003  3M India     25.00     33.44     22.77    19.44     10.43   \n",
       "\n",
       "      Feature6 Feature7  Feature8  ...  Feature22  Feature23  Feature24  \\\n",
       "18959    -4.97     2.07   8606.08  ...   2.876844     327.44     829.03   \n",
       "20893     2.37     0.51  10897.02  ...   3.853574     527.89     941.44   \n",
       "22046      NaN     0.83  14825.74  ...        NaN     793.04    1162.89   \n",
       "22474      NaN    -1.06  15342.12  ...        NaN     896.60    1295.80   \n",
       "23731      NaN    -0.28  24221.43  ...        NaN    1065.18    1708.67   \n",
       "176      43.72     0.97    329.65  ...   7.446352      11.38      15.83   \n",
       "860     298.14     0.56    655.91  ...  14.559600       7.14       9.84   \n",
       "1593    -38.04     0.02    743.71  ...  13.328136      24.80      29.19   \n",
       "2339     25.24     0.51    300.91  ...   4.323420      29.26      34.45   \n",
       "2980     11.21     1.02    340.97  ...   4.035626      35.74      38.04   \n",
       "\n",
       "       Feature25  Feature26  Feature27  Feature28   Target 1    Target 2   \\\n",
       "18959     788.01     286.42    8197.71    8838.10      -51.37      -39.33   \n",
       "20893     898.47     484.92    4234.86    5076.69       18.58       24.03   \n",
       "22046    1121.15     751.30    4914.95    5807.58        5.24       37.02   \n",
       "22474    1249.49     850.29    5001.57    6783.67       29.26         NaN   \n",
       "23731    1652.03    1008.54    6554.96    9471.93         NaN         NaN   \n",
       "176        13.67       9.22      74.01      29.74       55.24      117.63   \n",
       "860         7.14       4.44      72.16      27.11       38.26      -28.02   \n",
       "1593       24.43      20.04      99.86      44.06      -57.91      -39.35   \n",
       "2339       28.38      23.19     104.25      34.65       27.42       39.16   \n",
       "2980       32.15      29.85      88.01       3.52       -8.16      -15.63   \n",
       "\n",
       "        Target 3   \n",
       "18959      -32.05  \n",
       "20893        72.1  \n",
       "22046         NaN  \n",
       "22474         NaN  \n",
       "23731         NaN  \n",
       "176        -14.93  \n",
       "860        -12.02  \n",
       "1593       -75.53  \n",
       "2339         37.9  \n",
       "2980       -63.87  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "ba8feb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_impute = [\n",
    "    'Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', \n",
    "    'Feature6', 'Feature7', 'Feature8', 'Feature9', 'Feature10',\n",
    "    'Feature11', 'Feature12', 'Feature13', 'Feature14', 'Feature15',\n",
    "    'Feature16', 'Feature17', 'Feature18', 'Feature19', 'Feature20',\n",
    "    'Feature21', 'Feature22', 'Feature23', 'Feature24', 'Feature25',\n",
    "    'Feature26', 'Feature27', 'Feature28', ' Target 1 ', ' Target 2 ', ' Target 3 '\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "24cc204a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Feature4',\n",
       " 'Feature5',\n",
       " 'Feature6',\n",
       " 'Feature7',\n",
       " 'Feature9',\n",
       " ' Target 1 ',\n",
       " ' Target 2 ',\n",
       " ' Target 3 ']"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_col=[col for col in df.columns if df[col].dtype == 'object' and col not in ['Year', 'Company']]\n",
    "obj_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "ee87c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "df=df.replace([',','-',\" \"],\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "7b8e8004",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in obj_col:\n",
    "    df[col] = pd.to_numeric(\n",
    "    df[col].astype(str)\n",
    "            .str.replace(',', '', regex=True)   \n",
    "            .str.replace(' ', '', regex=True)   \n",
    "            .str.replace('-', '', regex=True)   \n",
    "            .replace('', np.nan),               \n",
    "    errors='coerce'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "64914016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 24751 entries, 18959 to 24067\n",
      "Data columns (total 33 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Year        24751 non-null  int64  \n",
      " 1   Company     24751 non-null  object \n",
      " 2   Feature1    20914 non-null  float64\n",
      " 3   Feature2    21999 non-null  float64\n",
      " 4   Feature3    22770 non-null  float64\n",
      " 5   Feature4    24204 non-null  float64\n",
      " 6   Feature5    24148 non-null  float64\n",
      " 7   Feature6    24050 non-null  float64\n",
      " 8   Feature7    24274 non-null  float64\n",
      " 9   Feature8    24751 non-null  float64\n",
      " 10  Feature9    23499 non-null  float64\n",
      " 11  Feature10   24025 non-null  float64\n",
      " 12  Feature11   24207 non-null  float64\n",
      " 13  Feature12   24292 non-null  float64\n",
      " 14  Feature13   24729 non-null  float64\n",
      " 15  Feature14   24716 non-null  float64\n",
      " 16  Feature15   24198 non-null  float64\n",
      " 17  Feature16   24625 non-null  float64\n",
      " 18  Feature17   24702 non-null  float64\n",
      " 19  Feature18   24625 non-null  float64\n",
      " 20  Feature19   24724 non-null  float64\n",
      " 21  Feature20   24384 non-null  float64\n",
      " 22  Feature21   24334 non-null  float64\n",
      " 23  Feature22   24564 non-null  float64\n",
      " 24  Feature23   24706 non-null  float64\n",
      " 25  Feature24   24705 non-null  float64\n",
      " 26  Feature25   24701 non-null  float64\n",
      " 27  Feature26   24702 non-null  float64\n",
      " 28  Feature27   24727 non-null  float64\n",
      " 29  Feature28   22719 non-null  float64\n",
      " 30   Target 1   22964 non-null  float64\n",
      " 31   Target 2   21409 non-null  float64\n",
      " 32   Target 3   19885 non-null  float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "f7c1f1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=7, weights='distance')\n",
    "\n",
    "\n",
    "df[cols_to_impute] = imputer.fit_transform(df[cols_to_impute])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "94e3b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# companies=df[\"Company\"].unique()\n",
    "# companies\n",
    "# X_seq, y_seq = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "a0398b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Company</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "      <th>Feature4</th>\n",
       "      <th>Feature5</th>\n",
       "      <th>Feature6</th>\n",
       "      <th>Feature7</th>\n",
       "      <th>Feature8</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature22</th>\n",
       "      <th>Feature23</th>\n",
       "      <th>Feature24</th>\n",
       "      <th>Feature25</th>\n",
       "      <th>Feature26</th>\n",
       "      <th>Feature27</th>\n",
       "      <th>Feature28</th>\n",
       "      <th>Target 1</th>\n",
       "      <th>Target 2</th>\n",
       "      <th>Target 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18959</th>\n",
       "      <td>2020</td>\n",
       "      <td>360 ONE</td>\n",
       "      <td>253.00</td>\n",
       "      <td>7.56</td>\n",
       "      <td>6.82</td>\n",
       "      <td>42.780000</td>\n",
       "      <td>5.290000</td>\n",
       "      <td>4.970000</td>\n",
       "      <td>2.07</td>\n",
       "      <td>8606.08</td>\n",
       "      <td>...</td>\n",
       "      <td>2.876844</td>\n",
       "      <td>327.44</td>\n",
       "      <td>829.03</td>\n",
       "      <td>788.01</td>\n",
       "      <td>286.42</td>\n",
       "      <td>8197.71</td>\n",
       "      <td>8838.10</td>\n",
       "      <td>51.370000</td>\n",
       "      <td>39.330000</td>\n",
       "      <td>32.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20893</th>\n",
       "      <td>2021</td>\n",
       "      <td>360 ONE</td>\n",
       "      <td>239.00</td>\n",
       "      <td>9.11</td>\n",
       "      <td>12.69</td>\n",
       "      <td>29.520000</td>\n",
       "      <td>23.550000</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>0.51</td>\n",
       "      <td>10897.02</td>\n",
       "      <td>...</td>\n",
       "      <td>3.853574</td>\n",
       "      <td>527.89</td>\n",
       "      <td>941.44</td>\n",
       "      <td>898.47</td>\n",
       "      <td>484.92</td>\n",
       "      <td>4234.86</td>\n",
       "      <td>5076.69</td>\n",
       "      <td>18.580000</td>\n",
       "      <td>24.030000</td>\n",
       "      <td>72.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22046</th>\n",
       "      <td>2022</td>\n",
       "      <td>360 ONE</td>\n",
       "      <td>1.86</td>\n",
       "      <td>13.40</td>\n",
       "      <td>19.75</td>\n",
       "      <td>60.174830</td>\n",
       "      <td>26.345488</td>\n",
       "      <td>145.183446</td>\n",
       "      <td>0.83</td>\n",
       "      <td>14825.74</td>\n",
       "      <td>...</td>\n",
       "      <td>5.289155</td>\n",
       "      <td>793.04</td>\n",
       "      <td>1162.89</td>\n",
       "      <td>1121.15</td>\n",
       "      <td>751.30</td>\n",
       "      <td>4914.95</td>\n",
       "      <td>5807.58</td>\n",
       "      <td>5.240000</td>\n",
       "      <td>37.020000</td>\n",
       "      <td>56.968732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22474</th>\n",
       "      <td>2023</td>\n",
       "      <td>360 ONE</td>\n",
       "      <td>2.05</td>\n",
       "      <td>13.34</td>\n",
       "      <td>21.41</td>\n",
       "      <td>53.754624</td>\n",
       "      <td>27.670162</td>\n",
       "      <td>63.309524</td>\n",
       "      <td>1.06</td>\n",
       "      <td>15342.12</td>\n",
       "      <td>...</td>\n",
       "      <td>4.569227</td>\n",
       "      <td>896.60</td>\n",
       "      <td>1295.80</td>\n",
       "      <td>1249.49</td>\n",
       "      <td>850.29</td>\n",
       "      <td>5001.57</td>\n",
       "      <td>6783.67</td>\n",
       "      <td>29.260000</td>\n",
       "      <td>50.657668</td>\n",
       "      <td>116.159864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23731</th>\n",
       "      <td>2024</td>\n",
       "      <td>360 ONE</td>\n",
       "      <td>2.47</td>\n",
       "      <td>14.47</td>\n",
       "      <td>24.48</td>\n",
       "      <td>113.536557</td>\n",
       "      <td>52.485771</td>\n",
       "      <td>79.485311</td>\n",
       "      <td>0.28</td>\n",
       "      <td>24221.43</td>\n",
       "      <td>...</td>\n",
       "      <td>5.798620</td>\n",
       "      <td>1065.18</td>\n",
       "      <td>1708.67</td>\n",
       "      <td>1652.03</td>\n",
       "      <td>1008.54</td>\n",
       "      <td>6554.96</td>\n",
       "      <td>9471.93</td>\n",
       "      <td>25.336492</td>\n",
       "      <td>49.163547</td>\n",
       "      <td>82.494157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Company  Feature1  Feature2  Feature3    Feature4   Feature5  \\\n",
       "18959  2020  360 ONE    253.00      7.56      6.82   42.780000   5.290000   \n",
       "20893  2021  360 ONE    239.00      9.11     12.69   29.520000  23.550000   \n",
       "22046  2022  360 ONE      1.86     13.40     19.75   60.174830  26.345488   \n",
       "22474  2023  360 ONE      2.05     13.34     21.41   53.754624  27.670162   \n",
       "23731  2024  360 ONE      2.47     14.47     24.48  113.536557  52.485771   \n",
       "\n",
       "         Feature6  Feature7  Feature8  ...  Feature22  Feature23  Feature24  \\\n",
       "18959    4.970000      2.07   8606.08  ...   2.876844     327.44     829.03   \n",
       "20893    2.370000      0.51  10897.02  ...   3.853574     527.89     941.44   \n",
       "22046  145.183446      0.83  14825.74  ...   5.289155     793.04    1162.89   \n",
       "22474   63.309524      1.06  15342.12  ...   4.569227     896.60    1295.80   \n",
       "23731   79.485311      0.28  24221.43  ...   5.798620    1065.18    1708.67   \n",
       "\n",
       "       Feature25  Feature26  Feature27  Feature28   Target 1    Target 2   \\\n",
       "18959     788.01     286.42    8197.71    8838.10   51.370000   39.330000   \n",
       "20893     898.47     484.92    4234.86    5076.69   18.580000   24.030000   \n",
       "22046    1121.15     751.30    4914.95    5807.58    5.240000   37.020000   \n",
       "22474    1249.49     850.29    5001.57    6783.67   29.260000   50.657668   \n",
       "23731    1652.03    1008.54    6554.96    9471.93   25.336492   49.163547   \n",
       "\n",
       "        Target 3   \n",
       "18959   32.050000  \n",
       "20893   72.100000  \n",
       "22046   56.968732  \n",
       "22474  116.159864  \n",
       "23731   82.494157  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "512314e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# first label and scale the train and test data \n",
    "# do not scale target cols \n",
    "# do not spilt the train data into x and y we do it when we make sequence\n",
    "# make sequence dropping year and comapny col\n",
    "# make embeddings for company and concatenate them with x_seq\n",
    "\n",
    "train_df = df[df['Year'] <= 2021] \n",
    "test_df  = df[df['Year'] > 2021]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "afc2206d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_932\\709352210.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['Company'] = encode.transform(train_df['Company'])\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_932\\709352210.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['Company']=encode.transform(test_df['Company'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "encode = LabelEncoder()\n",
    "encode.fit(df['Company'])\n",
    "train_df['Company'] = encode.transform(train_df['Company'])\n",
    "test_df['Company']=encode.transform(test_df['Company'])\n",
    "\n",
    "# mapping = {label: i for i, label in enumerate(encode.classes_)}\n",
    "# unknown_label = len(mapping)  \n",
    "\n",
    "# test_df['Company'] = test_df['Company'].map(lambda x: mapping.get(x, unknown_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "433bcdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies= df['Company'].unique()\n",
    "X_seq=[]\n",
    "y_seq=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "27171023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler=StandardScaler()\n",
    "# train_scaled=scaler.fit_transform(train_df.drop(columns=['Year', 'Company']))\n",
    "# test_scaled=scaler.transform(test_df.drop(columns=['Year', 'Company']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a670664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "64e18401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[cols_to_impute]=pd.DataFrame(train_df)\n",
    "# test_df[cols_to_impute]=pd.DataFrame(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "85677f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in df.columns if c not in ['Company', 'Year', ' Target 1 ',' Target 2 ',' Target 3 ']]\n",
    "target_cols = [' Target 1 ',' Target 2 ',' Target 3 ']\n",
    "\n",
    "seq_len_max = 5  \n",
    "\n",
    "X_seq = []\n",
    "y_seq = []\n",
    "companies_for_seq = []\n",
    "\n",
    "def create_variable_sequences(df, feature_cols, target_cols, seq_len_max=5):\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    companies_for_seq = []\n",
    "\n",
    "    for company, g in df.groupby('Company'):\n",
    "        g = g.sort_values('Year').reset_index(drop=True)\n",
    "        n_rows = len(g)\n",
    "        start_idx = 0\n",
    "\n",
    "        while start_idx < n_rows:\n",
    "            end_idx = min(start_idx + seq_len_max, n_rows)\n",
    "            \n",
    "           \n",
    "            X_window = g.loc[start_idx:end_idx-1, feature_cols].values\n",
    "           \n",
    "            y_window = g.loc[start_idx:end_idx-1, target_cols].values\n",
    "\n",
    "            X_seq.append(X_window)\n",
    "            y_seq.append(y_window)\n",
    "            companies_for_seq.append(company)\n",
    "            \n",
    "            start_idx = end_idx\n",
    "\n",
    "    return X_seq, y_seq, companies_for_seq\n",
    "\n",
    "\n",
    "seq_len_max = 5\n",
    "\n",
    "X_train_seq, y_train_seq, train_companies = create_variable_sequences(train_df, feature_cols, target_cols, seq_len_max)\n",
    "X_test_seq, y_test_seq, test_companies = create_variable_sequences(test_df, feature_cols, target_cols, seq_len_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "7c4204cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_seq_len = seq_len_max  \n",
    "num_features = X_train_seq[0].shape[1]\n",
    "\n",
    "\n",
    "X_train_padded = pad_sequences(\n",
    "    X_train_seq, \n",
    "    maxlen=max_seq_len, \n",
    "    dtype='float32', \n",
    "    padding='pre',    \n",
    "    value=0.0\n",
    ")\n",
    "\n",
    "X_test_padded = pad_sequences(\n",
    "    X_test_seq, \n",
    "    maxlen=max_seq_len, \n",
    "    dtype='float32', \n",
    "    padding='pre', \n",
    "    value=0.0\n",
    ")\n",
    "\n",
    "\n",
    "num_targets = y_train_seq[0].shape[1]\n",
    "\n",
    "y_train_padded = pad_sequences(\n",
    "    y_train_seq,\n",
    "    maxlen=max_seq_len,\n",
    "    dtype='float32',\n",
    "    padding='pre',\n",
    "    value=0.0\n",
    ")\n",
    "\n",
    "y_test_padded = pad_sequences(\n",
    "    y_test_seq,\n",
    "    maxlen=max_seq_len,\n",
    "    dtype='float32',\n",
    "    padding='pre',\n",
    "    value=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7810ac4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ sequence_input      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_10        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequence_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ company_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequence_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_13        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">44,736</span> │ company_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">23,808</span> │ masking_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ any_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_7        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">21,571</span> │ concatenate_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ sequence_input      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m28\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_10        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m28\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ sequence_input[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ company_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m28\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ sequence_input[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMasking\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any_13 (\u001b[38;5;33mAny\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ not_equal_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_13        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │     \u001b[38;5;34m44,736\u001b[0m │ company_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m23,808\u001b[0m │ masking_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ any_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_7        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │     \u001b[38;5;34m21,571\u001b[0m │ concatenate_15[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">90,115</span> (352.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m90,115\u001b[0m (352.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,731</span> (350.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,731\u001b[0m (350.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Embedding, Flatten, LSTM, Concatenate, Dense, Dropout, BatchNormalization, Masking\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping \n",
    "\n",
    "\n",
    "num_features = X_train_padded.shape[2]   \n",
    "num_targets = y_train_padded.shape[2]    \n",
    "num_companies = len(encode.classes_)\n",
    "embed_dim = 16\n",
    "lstm_units = 64\n",
    "max_seq_len = X_train_padded.shape[1]\n",
    "\n",
    "seq_input = Input(shape=(max_seq_len, num_features), name=\"sequence_input\")\n",
    "x_seq = Masking(mask_value=0.0)(seq_input)\n",
    "x_seq = LSTM(lstm_units, return_sequences=True)(x_seq)\n",
    "\n",
    "company_input = Input(shape=(1,), name=\"company_input\")\n",
    "company_embedding = Embedding(input_dim=num_companies, \n",
    "                              output_dim=embed_dim, \n",
    "                              input_length=1)(company_input)\n",
    "company_embedding = Flatten()(company_embedding)\n",
    "\n",
    "combined = Concatenate()([x_seq, company_embedding])\n",
    "\n",
    "dense_model = Sequential([\n",
    "    # Add L2 regularization to the Dense layers\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    # Increase dropout rate to combat severe overfitting\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    # Increase dropout rate\n",
    "    Dropout(0.4),\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dense(num_targets, activation='linear')\n",
    "])\n",
    "\n",
    "# --- Apply Sequential model on combined input ---\n",
    "output = dense_model(combined)\n",
    "\n",
    "# --- Build full model ---\n",
    "model = Model(inputs=[seq_input, company_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "# --- Implement EarlyStopping ---\n",
    "# It monitors the validation loss and stops training if it doesn't improve for 10 epochs.\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# --- Now, fit the model with the EarlyStopping callback ---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "07e9ef40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "169/169 - 4s - 23ms/step - loss: 79709.4922\n",
      "Epoch 2/200\n",
      "169/169 - 1s - 5ms/step - loss: 73073.1797\n",
      "Epoch 3/200\n",
      "169/169 - 1s - 5ms/step - loss: 70076.6797\n",
      "Epoch 4/200\n",
      "169/169 - 1s - 8ms/step - loss: 68109.3047\n",
      "Epoch 5/200\n",
      "169/169 - 1s - 6ms/step - loss: 65058.2695\n",
      "Epoch 6/200\n",
      "169/169 - 1s - 5ms/step - loss: 63291.2891\n",
      "Epoch 7/200\n",
      "169/169 - 1s - 4ms/step - loss: 62149.5977\n",
      "Epoch 8/200\n",
      "169/169 - 1s - 4ms/step - loss: 60559.8477\n",
      "Epoch 9/200\n",
      "169/169 - 1s - 4ms/step - loss: 60221.4531\n",
      "Epoch 10/200\n",
      "169/169 - 1s - 4ms/step - loss: 60344.3047\n",
      "Epoch 11/200\n",
      "169/169 - 1s - 4ms/step - loss: 59680.0547\n",
      "Epoch 12/200\n",
      "169/169 - 1s - 7ms/step - loss: 57836.9531\n",
      "Epoch 13/200\n",
      "169/169 - 1s - 4ms/step - loss: 57715.3672\n",
      "Epoch 14/200\n",
      "169/169 - 1s - 4ms/step - loss: 57106.0703\n",
      "Epoch 15/200\n",
      "169/169 - 1s - 5ms/step - loss: 55712.4102\n",
      "Epoch 16/200\n",
      "169/169 - 1s - 5ms/step - loss: 55459.8867\n",
      "Epoch 17/200\n",
      "169/169 - 1s - 5ms/step - loss: 54891.6289\n",
      "Epoch 18/200\n",
      "169/169 - 1s - 5ms/step - loss: 56202.7969\n",
      "Epoch 19/200\n",
      "169/169 - 1s - 5ms/step - loss: 52794.9805\n",
      "Epoch 20/200\n",
      "169/169 - 1s - 5ms/step - loss: 53750.1055\n",
      "Epoch 21/200\n",
      "169/169 - 1s - 5ms/step - loss: 53446.1016\n",
      "Epoch 22/200\n",
      "169/169 - 1s - 5ms/step - loss: 53714.6055\n",
      "Epoch 23/200\n",
      "169/169 - 1s - 5ms/step - loss: 52230.2930\n",
      "Epoch 24/200\n",
      "169/169 - 1s - 4ms/step - loss: 49969.5742\n",
      "Epoch 25/200\n",
      "169/169 - 1s - 4ms/step - loss: 52141.5273\n",
      "Epoch 26/200\n",
      "169/169 - 1s - 4ms/step - loss: 50693.7539\n",
      "Epoch 27/200\n",
      "169/169 - 1s - 5ms/step - loss: 50947.1641\n",
      "Epoch 28/200\n",
      "169/169 - 1s - 5ms/step - loss: 50790.8711\n",
      "Epoch 29/200\n",
      "169/169 - 1s - 4ms/step - loss: 52262.3320\n",
      "Epoch 30/200\n",
      "169/169 - 1s - 4ms/step - loss: 51866.6445\n",
      "Epoch 31/200\n",
      "169/169 - 1s - 6ms/step - loss: 49276.1094\n",
      "Epoch 32/200\n",
      "169/169 - 1s - 5ms/step - loss: 51499.1523\n",
      "Epoch 33/200\n",
      "169/169 - 1s - 5ms/step - loss: 47336.6953\n",
      "Epoch 34/200\n",
      "169/169 - 1s - 5ms/step - loss: 49250.9688\n",
      "Epoch 35/200\n",
      "169/169 - 1s - 5ms/step - loss: 46315.4961\n",
      "Epoch 36/200\n",
      "169/169 - 1s - 5ms/step - loss: 47169.9883\n",
      "Epoch 37/200\n",
      "169/169 - 1s - 5ms/step - loss: 47882.2422\n",
      "Epoch 38/200\n",
      "169/169 - 1s - 5ms/step - loss: 46957.0039\n",
      "Epoch 39/200\n",
      "169/169 - 1s - 4ms/step - loss: 48475.8203\n",
      "Epoch 40/200\n",
      "169/169 - 1s - 4ms/step - loss: 48983.4766\n",
      "Epoch 41/200\n",
      "169/169 - 1s - 5ms/step - loss: 44721.5898\n",
      "Epoch 42/200\n",
      "169/169 - 1s - 4ms/step - loss: 45154.7266\n",
      "Epoch 43/200\n",
      "169/169 - 1s - 4ms/step - loss: 46440.9570\n",
      "Epoch 44/200\n",
      "169/169 - 1s - 4ms/step - loss: 44349.1328\n",
      "Epoch 45/200\n",
      "169/169 - 1s - 4ms/step - loss: 46116.5820\n",
      "Epoch 46/200\n",
      "169/169 - 1s - 4ms/step - loss: 44070.4922\n",
      "Epoch 47/200\n",
      "169/169 - 1s - 4ms/step - loss: 45716.4219\n",
      "Epoch 48/200\n",
      "169/169 - 1s - 4ms/step - loss: 44097.7617\n",
      "Epoch 49/200\n",
      "169/169 - 1s - 4ms/step - loss: 45959.3633\n",
      "Epoch 50/200\n",
      "169/169 - 1s - 4ms/step - loss: 45817.9883\n",
      "Epoch 51/200\n",
      "169/169 - 1s - 4ms/step - loss: 44211.8789\n",
      "Epoch 52/200\n",
      "169/169 - 1s - 4ms/step - loss: 47686.9336\n",
      "Epoch 53/200\n",
      "169/169 - 1s - 4ms/step - loss: 46569.1602\n",
      "Epoch 54/200\n",
      "169/169 - 1s - 4ms/step - loss: 43140.2305\n",
      "Epoch 55/200\n",
      "169/169 - 1s - 4ms/step - loss: 41211.8633\n",
      "Epoch 56/200\n",
      "169/169 - 1s - 4ms/step - loss: 41527.8164\n",
      "Epoch 57/200\n",
      "169/169 - 1s - 4ms/step - loss: 41200.3008\n",
      "Epoch 58/200\n",
      "169/169 - 1s - 4ms/step - loss: 42105.7734\n",
      "Epoch 59/200\n",
      "169/169 - 1s - 5ms/step - loss: 40617.9609\n",
      "Epoch 60/200\n",
      "169/169 - 1s - 5ms/step - loss: 43166.0781\n",
      "Epoch 61/200\n",
      "169/169 - 1s - 4ms/step - loss: 40909.8008\n",
      "Epoch 62/200\n",
      "169/169 - 1s - 4ms/step - loss: 41035.0625\n",
      "Epoch 63/200\n",
      "169/169 - 1s - 4ms/step - loss: 40653.6992\n",
      "Epoch 64/200\n",
      "169/169 - 1s - 7ms/step - loss: 39840.0391\n",
      "Epoch 65/200\n",
      "169/169 - 1s - 4ms/step - loss: 41860.2461\n",
      "Epoch 66/200\n",
      "169/169 - 1s - 4ms/step - loss: 40618.9922\n",
      "Epoch 67/200\n",
      "169/169 - 1s - 4ms/step - loss: 40419.2305\n",
      "Epoch 68/200\n",
      "169/169 - 1s - 4ms/step - loss: 42761.8086\n",
      "Epoch 69/200\n",
      "169/169 - 1s - 4ms/step - loss: 43378.4688\n",
      "Epoch 70/200\n",
      "169/169 - 1s - 4ms/step - loss: 39615.8164\n",
      "Epoch 71/200\n",
      "169/169 - 1s - 4ms/step - loss: 36999.3984\n",
      "Epoch 72/200\n",
      "169/169 - 1s - 4ms/step - loss: 36430.1172\n",
      "Epoch 73/200\n",
      "169/169 - 1s - 4ms/step - loss: 36606.8828\n",
      "Epoch 74/200\n",
      "169/169 - 1s - 4ms/step - loss: 36992.0078\n",
      "Epoch 75/200\n",
      "169/169 - 1s - 4ms/step - loss: 36563.7070\n",
      "Epoch 76/200\n",
      "169/169 - 1s - 4ms/step - loss: 36460.2500\n",
      "Epoch 77/200\n",
      "169/169 - 1s - 4ms/step - loss: 36251.0742\n",
      "Epoch 78/200\n",
      "169/169 - 1s - 4ms/step - loss: 35461.0391\n",
      "Epoch 79/200\n",
      "169/169 - 1s - 4ms/step - loss: 35160.4336\n",
      "Epoch 80/200\n",
      "169/169 - 1s - 4ms/step - loss: 36477.6367\n",
      "Epoch 81/200\n",
      "169/169 - 1s - 5ms/step - loss: 37014.0820\n",
      "Epoch 82/200\n",
      "169/169 - 1s - 4ms/step - loss: 36328.8086\n",
      "Epoch 83/200\n",
      "169/169 - 1s - 4ms/step - loss: 37890.6055\n",
      "Epoch 84/200\n",
      "169/169 - 1s - 4ms/step - loss: 35664.1641\n",
      "Epoch 85/200\n",
      "169/169 - 1s - 4ms/step - loss: 38461.8047\n",
      "Epoch 86/200\n",
      "169/169 - 1s - 4ms/step - loss: 37039.2031\n",
      "Epoch 87/200\n",
      "169/169 - 1s - 5ms/step - loss: 34832.6562\n",
      "Epoch 88/200\n",
      "169/169 - 1s - 4ms/step - loss: 33543.8633\n",
      "Epoch 89/200\n",
      "169/169 - 1s - 4ms/step - loss: 33033.3672\n",
      "Epoch 90/200\n",
      "169/169 - 1s - 3ms/step - loss: 33934.1016\n",
      "Epoch 91/200\n",
      "169/169 - 1s - 4ms/step - loss: 35907.2305\n",
      "Epoch 92/200\n",
      "169/169 - 1s - 4ms/step - loss: 36996.9805\n",
      "Epoch 93/200\n",
      "169/169 - 1s - 4ms/step - loss: 38559.5898\n",
      "Epoch 94/200\n",
      "169/169 - 1s - 4ms/step - loss: 41657.4727\n",
      "Epoch 95/200\n",
      "169/169 - 1s - 4ms/step - loss: 37283.9062\n",
      "Epoch 96/200\n",
      "169/169 - 1s - 4ms/step - loss: 41094.1133\n",
      "Epoch 97/200\n",
      "169/169 - 1s - 4ms/step - loss: 39733.4570\n",
      "Epoch 98/200\n",
      "169/169 - 1s - 4ms/step - loss: 36120.8828\n",
      "Epoch 99/200\n",
      "169/169 - 1s - 4ms/step - loss: 35542.1914\n",
      "Epoch 100/200\n",
      "169/169 - 1s - 4ms/step - loss: 32919.8164\n",
      "Epoch 101/200\n",
      "169/169 - 1s - 4ms/step - loss: 37098.4688\n",
      "Epoch 102/200\n",
      "169/169 - 1s - 4ms/step - loss: 35395.0078\n",
      "Epoch 103/200\n",
      "169/169 - 1s - 4ms/step - loss: 36907.3984\n",
      "Epoch 104/200\n",
      "169/169 - 1s - 4ms/step - loss: 35682.6172\n",
      "Epoch 105/200\n",
      "169/169 - 1s - 4ms/step - loss: 34609.6250\n",
      "Epoch 106/200\n",
      "169/169 - 1s - 4ms/step - loss: 35194.9883\n",
      "Epoch 107/200\n",
      "169/169 - 1s - 4ms/step - loss: 38493.6602\n",
      "Epoch 108/200\n",
      "169/169 - 1s - 3ms/step - loss: 36186.8242\n",
      "Epoch 109/200\n",
      "169/169 - 1s - 4ms/step - loss: 32973.7461\n",
      "Epoch 110/200\n",
      "169/169 - 1s - 4ms/step - loss: 38095.2695\n",
      "Epoch 111/200\n",
      "169/169 - 1s - 4ms/step - loss: 34137.3906\n",
      "Epoch 112/200\n",
      "169/169 - 1s - 4ms/step - loss: 34023.9492\n",
      "Epoch 113/200\n",
      "169/169 - 1s - 5ms/step - loss: 32485.5430\n",
      "Epoch 114/200\n",
      "169/169 - 1s - 5ms/step - loss: 35290.2695\n",
      "Epoch 115/200\n",
      "169/169 - 1s - 4ms/step - loss: 34084.4414\n",
      "Epoch 116/200\n",
      "169/169 - 1s - 4ms/step - loss: 33586.6328\n",
      "Epoch 117/200\n",
      "169/169 - 1s - 4ms/step - loss: 31896.1855\n",
      "Epoch 118/200\n",
      "169/169 - 1s - 4ms/step - loss: 35538.2656\n",
      "Epoch 119/200\n",
      "169/169 - 1s - 4ms/step - loss: 32558.3359\n",
      "Epoch 120/200\n",
      "169/169 - 1s - 4ms/step - loss: 35746.5469\n",
      "Epoch 121/200\n",
      "169/169 - 1s - 4ms/step - loss: 31123.2383\n",
      "Epoch 122/200\n",
      "169/169 - 1s - 7ms/step - loss: 32895.7812\n",
      "Epoch 123/200\n",
      "169/169 - 1s - 4ms/step - loss: 34733.8242\n",
      "Epoch 124/200\n",
      "169/169 - 1s - 4ms/step - loss: 31088.0039\n",
      "Epoch 125/200\n",
      "169/169 - 1s - 4ms/step - loss: 34642.0742\n",
      "Epoch 126/200\n",
      "169/169 - 1s - 4ms/step - loss: 37704.8945\n",
      "Epoch 127/200\n",
      "169/169 - 1s - 4ms/step - loss: 36730.3633\n",
      "Epoch 128/200\n",
      "169/169 - 1s - 4ms/step - loss: 36913.6992\n",
      "Epoch 129/200\n",
      "169/169 - 1s - 4ms/step - loss: 35387.9141\n",
      "Epoch 130/200\n",
      "169/169 - 1s - 4ms/step - loss: 34859.3086\n",
      "Epoch 131/200\n",
      "169/169 - 1s - 4ms/step - loss: 35106.2695\n",
      "Epoch 132/200\n",
      "169/169 - 1s - 4ms/step - loss: 33421.8555\n",
      "Epoch 133/200\n",
      "169/169 - 1s - 4ms/step - loss: 31531.1797\n",
      "Epoch 134/200\n",
      "169/169 - 1s - 4ms/step - loss: 35175.6445\n",
      "Epoch 135/200\n",
      "169/169 - 1s - 4ms/step - loss: 31316.7793\n",
      "Epoch 136/200\n",
      "169/169 - 1s - 4ms/step - loss: 32483.3438\n",
      "Epoch 137/200\n",
      "169/169 - 1s - 4ms/step - loss: 34405.2773\n",
      "Epoch 138/200\n",
      "169/169 - 1s - 4ms/step - loss: 36290.7656\n",
      "Epoch 139/200\n",
      "169/169 - 1s - 4ms/step - loss: 33443.5000\n",
      "Epoch 140/200\n",
      "169/169 - 1s - 4ms/step - loss: 31343.9199\n",
      "Epoch 141/200\n",
      "169/169 - 1s - 4ms/step - loss: 34217.6523\n",
      "Epoch 142/200\n",
      "169/169 - 1s - 4ms/step - loss: 35887.4180\n",
      "Epoch 143/200\n",
      "169/169 - 1s - 4ms/step - loss: 33948.2500\n",
      "Epoch 144/200\n",
      "169/169 - 1s - 4ms/step - loss: 36501.4258\n",
      "Epoch 145/200\n",
      "169/169 - 1s - 4ms/step - loss: 30400.0898\n",
      "Epoch 146/200\n",
      "169/169 - 1s - 4ms/step - loss: 31351.2188\n",
      "Epoch 147/200\n",
      "169/169 - 1s - 4ms/step - loss: 31209.3613\n",
      "Epoch 148/200\n",
      "169/169 - 1s - 4ms/step - loss: 33554.8828\n",
      "Epoch 149/200\n",
      "169/169 - 1s - 4ms/step - loss: 32281.9160\n",
      "Epoch 150/200\n",
      "169/169 - 1s - 4ms/step - loss: 31874.1914\n",
      "Epoch 151/200\n",
      "169/169 - 1s - 4ms/step - loss: 30264.1582\n",
      "Epoch 152/200\n",
      "169/169 - 1s - 4ms/step - loss: 30765.7363\n",
      "Epoch 153/200\n",
      "169/169 - 1s - 4ms/step - loss: 31169.0020\n",
      "Epoch 154/200\n",
      "169/169 - 1s - 4ms/step - loss: 29762.6016\n",
      "Epoch 155/200\n",
      "169/169 - 1s - 4ms/step - loss: 30085.9863\n",
      "Epoch 156/200\n",
      "169/169 - 1s - 4ms/step - loss: 29860.7246\n",
      "Epoch 157/200\n",
      "169/169 - 1s - 4ms/step - loss: 28586.6055\n",
      "Epoch 158/200\n",
      "169/169 - 1s - 4ms/step - loss: 30148.7656\n",
      "Epoch 159/200\n",
      "169/169 - 1s - 4ms/step - loss: 30949.9453\n",
      "Epoch 160/200\n",
      "169/169 - 1s - 4ms/step - loss: 29163.5176\n",
      "Epoch 161/200\n",
      "169/169 - 1s - 4ms/step - loss: 30427.2598\n",
      "Epoch 162/200\n",
      "169/169 - 1s - 4ms/step - loss: 27216.7500\n",
      "Epoch 163/200\n",
      "169/169 - 1s - 4ms/step - loss: 30014.2930\n",
      "Epoch 164/200\n",
      "169/169 - 1s - 3ms/step - loss: 27670.3066\n",
      "Epoch 165/200\n",
      "169/169 - 1s - 4ms/step - loss: 29068.4395\n",
      "Epoch 166/200\n",
      "169/169 - 1s - 4ms/step - loss: 30644.2930\n",
      "Epoch 167/200\n",
      "169/169 - 1s - 4ms/step - loss: 27369.9043\n",
      "Epoch 168/200\n",
      "169/169 - 1s - 4ms/step - loss: 29746.0234\n",
      "Epoch 169/200\n",
      "169/169 - 1s - 4ms/step - loss: 27374.2305\n",
      "Epoch 170/200\n",
      "169/169 - 1s - 4ms/step - loss: 28561.5117\n",
      "Epoch 171/200\n",
      "169/169 - 1s - 4ms/step - loss: 26301.7754\n",
      "Epoch 172/200\n",
      "169/169 - 1s - 4ms/step - loss: 29156.5020\n",
      "Epoch 173/200\n",
      "169/169 - 1s - 4ms/step - loss: 28698.2520\n",
      "Epoch 174/200\n",
      "169/169 - 1s - 4ms/step - loss: 29271.2734\n",
      "Epoch 175/200\n",
      "169/169 - 1s - 4ms/step - loss: 31847.5625\n",
      "Epoch 176/200\n",
      "169/169 - 1s - 4ms/step - loss: 31418.2734\n",
      "Epoch 177/200\n",
      "169/169 - 1s - 4ms/step - loss: 27265.7480\n",
      "Epoch 178/200\n",
      "169/169 - 1s - 4ms/step - loss: 28306.8379\n",
      "Epoch 179/200\n",
      "169/169 - 1s - 4ms/step - loss: 28654.0273\n",
      "Epoch 180/200\n",
      "169/169 - 1s - 7ms/step - loss: 28666.6211\n",
      "Epoch 181/200\n",
      "169/169 - 1s - 4ms/step - loss: 33278.1367\n",
      "Epoch 182/200\n",
      "169/169 - 1s - 4ms/step - loss: 29399.1250\n",
      "Epoch 183/200\n",
      "169/169 - 1s - 4ms/step - loss: 30489.3496\n",
      "Epoch 184/200\n",
      "169/169 - 1s - 4ms/step - loss: 26576.9863\n",
      "Epoch 185/200\n",
      "169/169 - 1s - 5ms/step - loss: 28301.6367\n",
      "Epoch 186/200\n",
      "169/169 - 1s - 4ms/step - loss: 27237.7969\n",
      "Epoch 187/200\n",
      "169/169 - 1s - 4ms/step - loss: 27996.4160\n",
      "Epoch 188/200\n",
      "169/169 - 1s - 4ms/step - loss: 30184.7383\n",
      "Epoch 189/200\n",
      "169/169 - 1s - 3ms/step - loss: 26492.0000\n",
      "Epoch 190/200\n",
      "169/169 - 1s - 4ms/step - loss: 27621.8945\n",
      "Epoch 191/200\n",
      "169/169 - 1s - 3ms/step - loss: 28650.4746\n",
      "Epoch 192/200\n",
      "169/169 - 1s - 4ms/step - loss: 25140.2363\n",
      "Epoch 193/200\n",
      "169/169 - 1s - 4ms/step - loss: 25892.1465\n",
      "Epoch 194/200\n",
      "169/169 - 1s - 4ms/step - loss: 28087.5156\n",
      "Epoch 195/200\n",
      "169/169 - 1s - 4ms/step - loss: 28020.2715\n",
      "Epoch 196/200\n",
      "169/169 - 1s - 4ms/step - loss: 27856.7266\n",
      "Epoch 197/200\n",
      "169/169 - 1s - 4ms/step - loss: 31418.7012\n",
      "Epoch 198/200\n",
      "169/169 - 1s - 4ms/step - loss: 31481.0977\n",
      "Epoch 199/200\n",
      "169/169 - 1s - 4ms/step - loss: 29817.8652\n",
      "Epoch 200/200\n",
      "169/169 - 1s - 4ms/step - loss: 29795.7090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x13be8c3cec0>"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "y_train_reshaped = y_train_padded[:, -1, :]\n",
    "\n",
    "train_companies_np = np.array(train_companies)\n",
    "\n",
    "y_test_reshaped = y_test_padded[:, -1, :]\n",
    "\n",
    "test_companies_np = np.array(test_companies)\n",
    "\n",
    "model.fit(x=[X_train_padded, train_companies_np],\n",
    "          y=y_train_reshaped,\n",
    "          batch_size=32,\n",
    "          epochs=200,\n",
    "          verbose=2,\n",
    "        #   validation_data=([X_test_padded, test_companies_np], y_test_reshaped),\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5bdef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "2586a0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 73711.3125 \n",
      "Test Loss: 73711.3125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "loss = model.evaluate(\n",
    "    x=[X_test_padded, test_companies_np],\n",
    "    y=y_test_reshaped,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"Test Loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcfcec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c72ff9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85337a02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
